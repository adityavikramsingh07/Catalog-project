{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "5a4gUR4FYBQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report,\n",
        "    silhouette_score, adjusted_rand_score\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Our key import for building LLM embeddings: a Sentence Transformer model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Plotting configuration\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# LOAD DATASET (LOCALLY)\n",
        "# ---------------------------------------------------------\n",
        "print(\"Loading BBC News dataset from local file...\")\n",
        "\n",
        "# Replaced the URL with your local file name\n",
        "# Make sure 'BBC News Sample Solution.csv' matches the exact name of the file you uploaded\n",
        "df = pd.read_csv('BBC News Train.csv')\n",
        "\n",
        "print(f\"Dataset loaded: {len(df)} documents\")\n",
        "\n",
        "# Check if 'category' column exists before printing stats to avoid errors\n",
        "if 'category' in df.columns:\n",
        "    print(f\"Categories: {df['category'].unique()}\")\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    print(df['category'].value_counts())\n",
        "else:\n",
        "    print(\"Warning: The column 'category' was not found in this CSV.\")\n",
        "    print(\"Available columns:\", df.columns)"
      ],
      "metadata": {
        "id": "HiXWrUr0YNUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPARATION PRIOR TO GENERATING TEXT REPRESENTATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# FIX: Use Capitalized column names 'Text' and 'Category'\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['Category'].tolist()\n",
        "\n",
        "# Encoding labels for classification\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# Splitting data (same split for all representation methods and ML models trained later)\n",
        "X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
        "    texts, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set: {len(X_text_train)} | Test set: {len(X_text_test)}\")\n",
        "print(\"Classes found:\", le.classes_)"
      ],
      "metadata": {
        "id": "wrxjjMwiZCSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Representation 1: Bag-of-Words (BoW)**"
      ],
      "metadata": {
        "id": "XOxEcgJ_ZGDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1] Bag-of-Words...\")\n",
        "start = time()\n",
        "\n",
        "# The CountVectorizer class is used to apply BoW\n",
        "bow_vectorizer = CountVectorizer(\n",
        "    max_features=5000,\n",
        "    min_df=2,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_bow_train = bow_vectorizer.fit_transform(X_text_train)\n",
        "X_bow_test = bow_vectorizer.transform(X_text_test)\n",
        "\n",
        "bow_time = time() - start\n",
        "\n",
        "print(f\"   Done in {bow_time:.2f}s\")\n",
        "print(f\"   Shape: {X_bow_train.shape} (documents × vocabulary)\")\n",
        "print(f\"   Sparsity: {(1 - X_bow_train.nnz / (X_bow_train.shape[0] * X_bow_train.shape[1])) * 100:.1f}%\")\n",
        "print(f\"   Memory: {X_bow_train.data.nbytes / 1024:.1f} KB\")"
      ],
      "metadata": {
        "id": "ZARfM7yDZK_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Representation 2: TF-IDF**"
      ],
      "metadata": {
        "id": "rLXGV52xZg0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[2] TF-IDF...\")\n",
        "start = time()\n",
        "\n",
        "# Using TfidfVectorizer class to apply TF-IDF based on word frequencies\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    min_df=2,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_tfidf_train = tfidf_vectorizer.fit_transform(X_text_train)\n",
        "X_tfidf_test = tfidf_vectorizer.transform(X_text_test)\n",
        "\n",
        "tfidf_time = time() - start\n",
        "\n",
        "print(f\"   Done in {tfidf_time:.2f}s\")\n",
        "print(f\"   Shape: {X_tfidf_train.shape}\")\n",
        "print(f\"   Sparsity: {(1 - X_tfidf_train.nnz / (X_tfidf_train.shape[0] * X_tfidf_train.shape[1])) * 100:.1f}%\")\n",
        "print(f\"   Memory: {X_tfidf_train.data.nbytes / 1024:.1f} KB\")"
      ],
      "metadata": {
        "id": "fEO2ZkyjZimX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Representation 3: LLM Embeddings**"
      ],
      "metadata": {
        "id": "-vN7ePDGb1PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- FIX: Define X_text_train before using it ---\n",
        "# (Assuming 'df' is loaded. If not, run df = pd.read_csv('BBC News Train.csv') first)\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['Category'].tolist()\n",
        "y = LabelEncoder().fit_transform(labels)\n",
        "\n",
        "X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
        "    texts, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "# ------------------------------------------------\n",
        "\n",
        "print(\"\\n[3] LLM Embeddings...\")\n",
        "start = time()\n",
        "\n",
        "# Loading a pre-trained sentence transformer model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "X_emb_train = embedding_model.encode(\n",
        "    X_text_train,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=32\n",
        ")\n",
        "X_emb_test = embedding_model.encode(\n",
        "    X_text_test,\n",
        "    show_progress_bar=False,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "emb_time = time() - start\n",
        "\n",
        "print(f\"   Done in {emb_time:.2f}s\")\n",
        "print(f\"   Shape: {X_emb_train.shape} (documents × embedding_dim)\")\n",
        "print(f\"   Sparsity: 0.0% (dense representation)\")\n",
        "print(f\"   Memory: {X_emb_train.nbytes / 1024:.1f} KB\")"
      ],
      "metadata": {
        "id": "lRLsUKI8boda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison 1: Text Classification**"
      ],
      "metadata": {
        "id": "Qu0X1b83cCmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON 1: SUPERVISED CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Defining the three types of classifiers to train\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(kernel='linear', random_state=42)\n",
        "}\n",
        "\n",
        "# Storing results in a Python collection (list)\n",
        "classification_results = []\n",
        "\n",
        "# Evaluating each representation with each classifier\n",
        "representations = {\n",
        "    'BoW': (X_bow_train, X_bow_test),\n",
        "    'TF-IDF': (X_tfidf_train, X_tfidf_test),\n",
        "    'LLM Embeddings': (X_emb_train, X_emb_test)\n",
        "}\n",
        "\n",
        "for rep_name, (X_tr, X_te) in representations.items():\n",
        "    print(f\"\\nTesting {rep_name}:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        # Train\n",
        "        start = time()\n",
        "        clf.fit(X_tr, y_train)\n",
        "        train_time = time() - start\n",
        "\n",
        "        # Predict\n",
        "        start = time()\n",
        "        y_pred = clf.predict(X_te)\n",
        "        pred_time = time() - start\n",
        "\n",
        "        # Evaluate\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        print(f\"   {clf_name:20s} | Acc: {acc:.3f} | F1: {f1:.3f} | Train: {train_time:.2f}s\")\n",
        "\n",
        "        classification_results.append({\n",
        "            'Representation': rep_name,\n",
        "            'Classifier': clf_name,\n",
        "            'Accuracy': acc,\n",
        "            'F1-Score': f1,\n",
        "            'Train Time': train_time,\n",
        "            'Predict Time': pred_time\n",
        "        })\n",
        "\n",
        "# Converting results to DataFrame for interpretability and easier comparison\n",
        "results_df = pd.DataFrame(classification_results)"
      ],
      "metadata": {
        "id": "ZgyGiYgrcFR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input code for visualizing results:**"
      ],
      "metadata": {
        "id": "VG8NsW2scSBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating visualization plots for direct comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Accuracy comparison\n",
        "pivot_acc = results_df.pivot(index='Classifier', columns='Representation', values='Accuracy')\n",
        "pivot_acc.plot(kind='bar', ax=axes[0], width=0.8)\n",
        "axes[0].set_title('Classification Accuracy by Representation', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_xlabel('Classifier')\n",
        "axes[0].legend(title='Representation')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "axes[0].set_ylim([0.9, 1.0])\n",
        "\n",
        "# Plot 2: Training time comparison\n",
        "pivot_time = results_df.pivot(index='Classifier', columns='Representation', values='Train Time')\n",
        "pivot_time.plot(kind='bar', ax=axes[1], width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "axes[1].set_title('Training Time by Representation', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Time (seconds)')\n",
        "axes[1].set_xlabel('Classifier')\n",
        "axes[1].legend(title='Representation')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identifying best performers\n",
        "print(\"\\nBEST PERFORMERS:\")\n",
        "print(\"-\" * 50)\n",
        "best_acc = results_df.loc[results_df['Accuracy'].idxmax()]\n",
        "print(f\"Best Accuracy: {best_acc['Representation']} + {best_acc['Classifier']} = {best_acc['Accuracy']:.3f}\")\n",
        "\n",
        "fastest = results_df.loc[results_df['Train Time'].idxmin()]\n",
        "print(f\"Fastest Training: {fastest['Representation']} + {fastest['Classifier']} = {fastest['Train Time']:.2f}s\")"
      ],
      "metadata": {
        "id": "92gnOQsxcT0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison 2: Document Clustering**"
      ],
      "metadata": {
        "id": "0BdrQ_sUcZhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON 2: DOCUMENT CLUSTERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Using full dataset for clustering (no train/test split needed)\n",
        "all_texts = texts\n",
        "all_labels = y\n",
        "\n",
        "# Generating representations once more\n",
        "print(\"\\nGenerating representations for full dataset...\")\n",
        "\n",
        "X_bow_full = bow_vectorizer.fit_transform(all_texts)\n",
        "X_tfidf_full = tfidf_vectorizer.fit_transform(all_texts)\n",
        "X_emb_full = embedding_model.encode(all_texts, show_progress_bar=True, batch_size=32)\n",
        "\n",
        "# Clustering with K-Means (k=5, matching ground-truth categories)\n",
        "n_clusters = len(np.unique(all_labels))\n",
        "clustering_results = []\n",
        "\n",
        "representations_full = {\n",
        "    'BoW': X_bow_full,\n",
        "    'TF-IDF': X_tfidf_full,\n",
        "    'LLM Embeddings': X_emb_full\n",
        "}\n",
        "\n",
        "for rep_name, X_full in representations_full.items():\n",
        "    print(f\"\\nClustering with {rep_name}:\")\n",
        "\n",
        "    start = time()\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(X_full)\n",
        "    cluster_time = time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    silhouette = silhouette_score(X_full, cluster_labels)\n",
        "    ari = adjusted_rand_score(all_labels, cluster_labels)\n",
        "\n",
        "    print(f\"   Silhouette Score: {silhouette:.3f}\")\n",
        "    print(f\"   Adjusted Rand Index: {ari:.3f}\")\n",
        "    print(f\"   Time: {cluster_time:.2f}s\")\n",
        "\n",
        "    clustering_results.append({\n",
        "        'Representation': rep_name,\n",
        "        'Silhouette': silhouette,\n",
        "        'ARI': ari,\n",
        "        'Time': cluster_time\n",
        "    })\n",
        "\n",
        "clustering_df = pd.DataFrame(clustering_results)"
      ],
      "metadata": {
        "id": "ZMsUhVbRcbJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for visualizing results:**"
      ],
      "metadata": {
        "id": "qZ2UAtUsclac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating comparison plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Clustering quality metrics\n",
        "x = np.arange(len(clustering_df))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, clustering_df['Silhouette'], width, label='Silhouette', alpha=0.8)\n",
        "axes[0].bar(x + width/2, clustering_df['ARI'], width, label='Adjusted Rand Index', alpha=0.8)\n",
        "axes[0].set_xlabel('Representation')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Clustering Quality Metrics', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(clustering_df['Representation'])\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: Clustering time\n",
        "axes[1].bar(clustering_df['Representation'], clustering_df['Time'], color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8)\n",
        "axes[1].set_xlabel('Representation')\n",
        "axes[1].set_ylabel('Time (seconds)')\n",
        "axes[1].set_title('Clustering Computation Time', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nBEST CLUSTERING PERFORMER:\")\n",
        "print(\"-\" * 50)\n",
        "best_cluster = clustering_df.loc[clustering_df['ARI'].idxmax()]\n",
        "print(f\"{best_cluster['Representation']}: ARI = {best_cluster['ARI']:.3f}, Silhouette = {best_cluster['Silhouette']:.3f}\")"
      ],
      "metadata": {
        "id": "gqbgVFQWcnB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}